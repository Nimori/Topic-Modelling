{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "\n",
    "from string import punctuation\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('query_result_2020-09-11T11_40_36.049226Z.csv')\n",
    "type(df['post_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator= Translator()\n",
    "translations= {}\n",
    "unique_elements= df['post_description'].unique()\n",
    "\n",
    "for element in unique_elements:\n",
    "    translations[element] = translator.translate(element).text\n",
    "#translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans= translations.values()\n",
    "#trans\n",
    "df['post_description_en']= trans\n",
    "df['post_description_en']= df['post_description_en'].str.lower()\n",
    "df2= df['post_description_en'].str.replace(r'\\W', ' ') #to remove any undesired special characters\n",
    "#df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_des= df2.tolist()\n",
    "#post_des\n",
    "post_preprocess= []\n",
    "for i in post_des:\n",
    "    post_preprocess.append(gensim.utils.simple_preprocess(i, deacc= True))\n",
    "#post_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= post_des\n",
    "stops= set(stopwords.words('english'))\n",
    "translate_tab = {ord(p): u\" \" for p in punctuation}\n",
    "\n",
    "############### defining process_texts function ##############\n",
    "def process_texts(texts):\n",
    "    texts= [[word for word in line if word not in stops] for line in texts]\n",
    "    #texts= texts.translate(translate_tab)\n",
    "    #tokens = [token.strip() for token in tokenizer.tokenize(texts)]\n",
    "    #tokens = [token for token in tokens if token not in eng_stopwords]\n",
    "    #stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts= process_texts(post_preprocess)\n",
    "#train_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts2= []\n",
    "for token in train_texts:\n",
    "    t= []\n",
    "    for word in token:\n",
    "        k= False\n",
    "        for i in word:\n",
    "            if(ord(i)<65 & ord(i)>97):\n",
    "                k= True\n",
    "                break\n",
    "        if(k== True):\n",
    "            continue\n",
    "        else:\n",
    "            t.append(word)\n",
    "    texts2.append(t)\n",
    "#texts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "newsgroups = fetch_20newsgroups()\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "stemmer = PorterStemmer()\n",
    "translate_tab = {ord(p): u\" \" for p in punctuation}\n",
    "\n",
    "\n",
    "def text2tokens(raw_text):\n",
    "    \"\"\"Convert a raw text to a list of stemmed tokens.\"\"\"\n",
    "    clean_text = raw_text.lower().translate(translate_tab)\n",
    "    tokens = [token.strip() for token in tokenizer.tokenize(clean_text)]\n",
    "    tokens = [token for token in tokens if token not in eng_stopwords]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return [token for token in stemmed_tokens if len(token) > 2]  # skip short tokens\n",
    "\n",
    "dataset = [text2tokens(txt) for txt in newsgroups['data']]  # convert a documents to list of tokens\n",
    "\n",
    "dictionary2 = Dictionary(documents=dataset, prune_at=None)\n",
    "dictionary2.filter_extremes(no_below=5, no_above=0.3, keep_n=None)  # use Dictionary to remove un-relevant tokens\n",
    "dictionary2.compactify()\n",
    "\n",
    "d2b_dataset = [dictionary2.doc2bow(doc) for doc in dataset]\n",
    "corpus2= d2b_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary= Dictionary(texts)\n",
    "corpus= [dictionary2.doc2bow(text) for text in texts]\n",
    "\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def topic():\n",
    "    score= {}\n",
    "\n",
    "    for num_topic in range(3, 20):\n",
    "        lda_model= LdaModel(corpus= corpus2, num_topics= num_topic, id2word= dictionary2)\n",
    "        \n",
    "        ################# coherence score ########################\n",
    "        coherence_model_lda = CoherenceModel(\n",
    "           model=lda_model, texts=dataset, dictionary= dictionary2, coherence='c_v'\n",
    "        )\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        #print('\\nCoherence Score: ', coherence_lda)\n",
    "        score[num_topic]= coherence_lda\n",
    "    return sorted(score.items(), key= lambda x:x[1])[-1][0], score\n",
    "topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model= LdaModel(corpus= corpus2, num_topics= 11, id2word= dictionary2)\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Probability of a news to be categorized into correct topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(lda_model, corpus2, dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= []\n",
    "prob= []\n",
    "for i, row in enumerate(lda_model[corpus]):\n",
    "   row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "   print(row)\n",
    "   pred.append(row[0][0])\n",
    "   prob.append(row[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prob'] = prob\n",
    "df['cluster'] = pred\n",
    "df[['post_description_en', 'cluster']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
